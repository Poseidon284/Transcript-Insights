{"cells":[{"cell_type":"markdown","metadata":{"id":"nSzGe7XD65i3"},"source":["# Data Ingestion #"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":429,"status":"ok","timestamp":1726408420811,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"1sW26BnS7SX0","outputId":"d18d88f4-9975-47b5-f129-78516fae54ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected file: /content/Radhesh_CNN_ImageClassificationProject.mp4\n","MIME type: video/mp4\n"]}],"source":["from google.colab import files\n","import mimetypes\n","\n","file_path = '/content/Radhesh_CNN_ImageClassificationProject.mp4'\n","\n","mime_type, _ = mimetypes.guess_type(file_path)\n","\n","print(f\"Selected file: {file_path}\")\n","print(f\"MIME type: {mime_type or 'Unknown'}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5324,"status":"ok","timestamp":1726409621352,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"-ahuPpz5B_UQ","outputId":"b0a39db8-2af1-476c-e796-b7e2caa31b31"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.45.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n","Downloading openai-1.45.0-py3-none-any.whl (374 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.1/374.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.45.0\n"]}],"source":["!pip install openai moviepy"]},{"cell_type":"markdown","metadata":{"id":"SUJuNmGKHY85"},"source":["# Transcription"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19995,"status":"ok","timestamp":1726409784384,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"KMuI-oEM9gNc","outputId":"167b7be7-c55e-40e3-e047-5dbc56a1c7f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["MoviePy - Writing audio in output_audio.mp3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                       "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]}],"source":["from openai import OpenAI\n","from moviepy.editor import VideoFileClip\n","\n","client = OpenAI(api_key=OPEN_AI_KEY)\n","if \"video\" in mime_type or \"mp3\" not in mime_type:\n","  video = VideoFileClip(file_path)\n","  audio = video.audio\n","  audio.write_audiofile(\"output_audio.mp3\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"collapsed":true,"executionInfo":{"elapsed":4662,"status":"error","timestamp":1726409807399,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"I2d-xb_KCtLl","outputId":"a01392c8-f2c4-43d2-ea00-874a5bacdc27"},"outputs":[],"source":["audio_file= open(\"output_audio.mp3\", \"rb\")\n","transcript = client.audio.transcriptions.create(\n","  model=\"whisper-1\",\n","  file=audio_file,\n","  prompt=\"The audio is from a panel discussion which may have multiple speakers and multiple topics\"\n",")\n","\n","print(transcript.text)"]},{"cell_type":"markdown","metadata":{"id":"VWrsKP9bHiNC"},"source":["# Topic Extraction"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1259,"status":"ok","timestamp":1726444783423,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"nr0XfeLdD2GJ","outputId":"79ddbfd7-8ad3-4386-e667-fc5f0f1ce919"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]},{"data":{"text/plain":["True"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","from nltk.stem import *\n","nltk.download('punkt') # For Stemming\n","nltk.download('wordnet') # For Lemmatization\n","nltk.download('stopwords') # For Stopword Removal\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1726444788033,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"hTku4F5sH5yc"},"outputs":[],"source":["stopwords = set(nltk.corpus.stopwords.words('english'))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11459,"status":"ok","timestamp":1726444876529,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"qm0o6FTcIfIY"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.datasets import fetch_20newsgroups\n","fetch20newsgroups = fetch_20newsgroups(subset='train')\n","# Store in a pandas dataframe\n","df = pd.DataFrame(fetch20newsgroups.data, columns=['text'])"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":49853,"status":"ok","timestamp":1726447130339,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"8U2KGLD0Qyf4"},"outputs":[],"source":["def text_preprocessing(df):\n","    corpus=[]\n","    lem = WordNetLemmatizer() # For Lemmatization\n","    for news in df['text']:\n","        words=[w for w in nltk.tokenize.word_tokenize(news) if (w not in stopwords)]\n","        words=[lem.lemmatize(w) for w in words if len(w)>2]\n","        corpus.append(words)\n","    return corpus\n","\n","corpus = text_preprocessing(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21898,"status":"ok","timestamp":1726447156040,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"1Yo0xcogRF0P","outputId":"d4546bcd-98c7-453c-f8bd-cd74571ea4a0"},"outputs":[],"source":["!pip install -U gensim==3.8.3"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":15711,"status":"ok","timestamp":1726447171748,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"uWOU9HWNREbJ"},"outputs":[],"source":["import gensim\n","# Transform to gensim dictionary\n","dic = gensim.corpora.Dictionary(corpus)\n","bow_corpus = [dic.doc2bow(doc) for doc in corpus]\n","import pickle # Useful for storing big datasets\n","pickle.dump(bow_corpus, open('corpus.pkl', 'wb'))\n","dic.save('dictionary.gensim')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94324,"status":"ok","timestamp":1726447870813,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"6u44RlLyRR6r","outputId":"a9f8ffe5-d641-4eb6-8428-7bcdf0911d7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Topic: 0 \n","Words: 0.008*\"The\" + 0.008*\"n't\" + 0.006*\"From\" + 0.006*\"Subject\" + 0.006*\"Lines\" + 0.006*\"Organization\" + 0.005*\"would\" + 0.004*\"one\" + 0.004*\"writes\" + 0.004*\"...\" + 0.004*\"article\" + 0.003*\"people\" + 0.003*\"like\" + 0.003*\"know\" + 0.003*\"University\" + 0.003*\"get\" + 0.002*\"think\" + 0.002*\"time\" + 0.002*\"This\" + 0.002*\"use\"\n","Topic: 1 \n","Words: 0.189*\"'AX\" + 0.014*\"MAX\" + 0.004*\"Q,3\" + 0.003*\"B8F\" + 0.003*\"A86\" + 0.003*\"145\" + 0.002*\"1D9\" + 0.001*\"2DI\" + 0.001*\"BHJ\" + 0.001*\"PL+\" + 0.001*\"GIZ\" + 0.001*\"From\" + 0.001*\"0T-\" + 0.001*\"Subject\" + 0.001*\"Organization\" + 0.001*\"Lines\" + 0.001*\"/3T\" + 0.001*\"7EY\" + 0.001*\"6UM\" + 0.001*\"output\"\n"]}],"source":["#LDA model\n","lda_model2 = gensim.models.LdaMulticore(bow_corpus,\n","                                    num_topics = 2,\n","                                     id2word = dic,\n","                                        passes = 8,\n","                                       workers = 3)\n","lda_model2.save('model2.gensim')\n","# We print words occuring in each of the topics as we iterate through them\n","for idx, topic in lda_model2.print_topics(num_words=20):\n","  print('Topic: {} \\nWords: {}'.format(idx, topic))"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24427,"status":"ok","timestamp":1726447961213,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"D0bfCVL8TO23","outputId":"497e523e-40db-401a-a1fb-2a002f8be5f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5623304946981044\n"]}],"source":["from gensim.models import CoherenceModel\n","# instantiate topic coherence model\n","cm = CoherenceModel(model=lda_model2, corpus=bow_corpus, texts=corpus, coherence='c_v')\n","# get topic coherence score\n","coherence_lda = cm.get_coherence()\n","print(coherence_lda)"]},{"cell_type":"markdown","metadata":{"id":"7zyD6GwiWHc6"},"source":["# LLM Integration"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1726449853459,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"nodJHzH2WKah"},"outputs":[],"source":["def summarize(context,input):\n","\n","        prompt = f\"\"\"As a professional summarizer, create a concise and comprehensive summary of the provided text, which can be a panel discussion or a customer-agent conversation while adhering to these guidelines: \\\n","        * Craft a summary that is detailed, thorough, in-depth, and complex, while maintaining clarity and conciseness. \\\n","        * If there are multiple speakers, count the number of speakers. \\\n","        * Count the number of words spoken and mention any key words with their count as well. \\\n","        * Incorporate main ideas and essential information, eliminating extraneous language and focusing on critical aspects. \\\n","        * IMPORTANT: \"If the given context is irrelevant to the answer, generate an answer based on the question given and kindly mention that this answer is not a part of the given transcript\". Otherwise, rely strictly on the provided context, without including external information. \\\n","        * Format the summary in paragraph form for easy understanding.  \\\n","        * Give a descriptive title \\\n","        * Use bullet points if and only if there are any procedures or step by step information in the given passage. \\\n","        context: {context}\n","        input: {input}\n","        \"\"\"\n","\n","        return prompt"]},{"cell_type":"markdown","metadata":{"id":"xDHDcY5oYjKg"},"source":["## LLM Call"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":12556,"status":"ok","timestamp":1726449368451,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"RKSlL6BeZngs","outputId":"82234f81-f08e-46bc-e2d3-ef7eb6fae58b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain\n","  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.7.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.34)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.5)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-core<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.1)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.6)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n","Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m930.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.0)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.48.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n","Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.8/289.8 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, h11, jsonpatch, httpcore, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-core-0.3.0 langchain-text-splitters-0.3.0 langsmith-0.1.120 orjson-3.10.7 tenacity-8.5.0\n"]}],"source":["!pip install langchain google-generativeai"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":5057,"status":"ok","timestamp":1726449663844,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"sPqA58xtaxV6","outputId":"0160508e-db20-4d54-9c85-2bb2b5bb37c6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_google_genai\n","  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n","Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.7.2)\n","Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.3.0)\n","Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (2.9.1)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.6)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.19.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.137.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.1.120)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (24.1)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_google_genai) (8.5.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.23.3)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.10.7)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (3.8)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (0.14.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.0.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain_google_genai) (1.2.2)\n","Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n","Installing collected packages: langchain_google_genai\n","Successfully installed langchain_google_genai-2.0.0\n"]}],"source":["!pip install langchain_google_genai"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":382,"status":"ok","timestamp":1726452648117,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"ORT_cVaklwfY","outputId":"46462558-8f7d-4d2f-aaa7-dedddc26b42f"},"outputs":[{"name":"stdout","output_type":"stream","text":["First Speaker: To tell you basically what this is about is when I was watching Harvey Mackay at one of Harv Eker's things, he said he just finished the Boston marathon and you know, the guy is 76 and I went holy crap, you know, that is amazing. He looked so fit and he is so quick minded and so on I thought, all of a sudden it occurred to me I bet the way you eat, you know, is different. I bet you don't just eat a bunch of garbage and that started this thought. So, the basic three questions will be and I am recording it for you as well if I transcribe these for the book, but then I write about it and what has really been neat about it is that what started out as three same questions to everybody, everybody had kind of a different angle on it and I realized that they were creating the chapters for this book and of course Marci Shimoff read me right [???], I am not doing something where I did all the work and you are just transcribing it, but if you actually write in the book, I will do it. So I made her that promise and it was a hard promise, but it was a good one to make because it made me think more, you know.\n","\n","Second Speaker: Got you.\n","\n","First Speaker: So, what I would do is I basically introduce you and then you can add anything that you think is important to that introduction and let me get my history up here because I have you on here. So, how is Robby doing?\n","\n","Second Speaker: Good, hangin' in there.\n","\n","First Speaker: Yeah, did you guys have a nice holiday?\n","\n","Second Speaker: Well, we actually kind of had a [???] holiday, her father who is very old got sick and ended up passing away.\n","\n","First Speaker: Oh I am sorry to hear that.\n","\n","Second Speaker: But, you know, stuff happens, what are you going to do?\n","\n","First Speaker: So I am going to – is your best website, at the end I am going to ask you, you know, about your website and stuff, is rickfrishman.com the best one to go to or -\n","\n","Second Speaker: Yeah probably just for most stuff that is probably the best way to go yeah.\n","\n","First Speaker: You had a really good bio on one of your websites.\n","\n","Second Speaker: It is up there, there is one, you know, in most of them. I also have rickfrishmanblog.com, you know.\n","\n","First Speaker: Let me check that out, okay so the -\n","\n","Second Speaker: There is a bio on that one, but it is also a bio on just rickfrishman.com.\n","\n","First Speaker: There we go about Rick, yeah.\n","\n","Second Speaker: Sure.\n","\n","First Speaker: So you know, one of the things that I will bring up is, you know, you always talk about how you have the biggest Rolodex and I thought that was a really cool angle too because part of success is who you know and you know, I think that is important. I don't know what your angle is going to be on this, but you know, the questions will be do you think that that hypothesis is true that, you know, food affects your ability to succeed on some level and then if you -\n","\n","Second Speaker: Food affects your ability to -\n","\n","First Speaker: You know, if it plays into your level of success. In other words, you know, I know there are successful people who eat crappy food, but so far kind of the consensus has been, you know, it has run the gamut of extremes, but so far people seem to say, you know, they can't keep up their energy if you speak a lot. You do a lot of speaking so you know, and you have a hectic schedule, so I imagine that if you are, you know, full of two pizzas, you probably don't have the energy on stage that you normally would.\n","\n","Second Speaker: Right, it is true.\n"]}],"source":["file1 = open(\"transcript.txt\",\"r\")\n","transcript = \"\".join(file1.readlines())\n","print(transcript)"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4253,"status":"ok","timestamp":1726453117768,"user":{"displayName":"Radhesh Rathnam","userId":"13526431739082962022"},"user_tz":-330},"id":"ulDJUCopYh_h","outputId":"1b197593-e301-49e1-a406-2210b31687ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["**Summary: Nutrition and Success**\n","\n","**Number of Speakers:** 2\n","\n","**Number of Words Spoken:** 325\n","\n","**Key Words:**\n","* Success: 4\n","* Food: 4\n","* Energy: 2\n","* Rolodex: 1\n","\n","**Main Ideas:**\n","\n","* The discussion begins with a reference to Harvey Mackay's fitness and quick-mindedness, leading to the hypothesis that his diet may contribute to his success.\n","* The three questions to be discussed include:\n","    * Does food affect one's ability to succeed?\n","    * If so, how does it play into their level of success?\n","    * Can people maintain high energy levels while consuming unhealthy food?\n","\n","**Essential Information:**\n","\n","* The first speaker introduces the second speaker, Rick Frishman, and mentions his extensive network (\"the biggest Rolodex\").\n","* Frishman's website, rickfrishman.com, is recommended for general information.\n","* Frishman agrees with the hypothesis that food can impact success, particularly in terms of energy levels for public speaking and hectic schedules.\n","* While some successful people may consume unhealthy food, the consensus among previous interviewees has been that a nutritious diet supports sustained energy and performance.\n"]}],"source":["import google.generativeai as genai\n","import google.ai.generativelanguage as glm\n","from langchain.prompts import PromptTemplate\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain.chains import create_retrieval_chain\n","from langchain_google_genai import ChatGoogleGenerativeAI\n","\n","API_KEY = gemini_API\n","input=\"Create a summary of the entire discussion\"\n","template = summarize(context=\"{context}\",input=\"{input}\")\n","llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key = API_KEY)\n","prompt = PromptTemplate.from_template(template)\n","chain = prompt | llm\n","response = chain.invoke({\"context\":transcript,\"input\":input})\n","print(response.content)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPiBVzmCPC3Mb8oo8Ky2H8z","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
